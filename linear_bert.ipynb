{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel, TFBertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique label values: {'Severability', 'compensation', 'Entire', 'grant', 'investment_company', 'Assignment', 'employee_benefits', 'payment', 'base-salary', 'Confidentiality', 'WHEREAS', 'stock_option', 'seed', 'Insurance', 'conversion_of_shares', 'payment_terms', 'financing', 'grant_of_option', 'investment-company-act', 'Headings', 'investments', 'Miscellaneous', 'ownership_of_shares', 'Governing', 'private_equity', 'Definitions', 'taxes', 'shares', 'Representations', 'capitalization', 'Termination', 'NOW', 'esop', 'foreign_investors', 'dividends', 'loans', 'Indemnification', 'Counterparts', 'Notices', 'board', 'interest', 'vesting'}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"contracts-clauses-datasets.csv\")\n",
    "sentences = data[\"Text\"].values\n",
    "labels = data[\"Label\"].values\n",
    "data_top = data.head() \n",
    "data_top \n",
    "\n",
    "def convert_labels(labels):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        try:\n",
    "            new_label = int(label)\n",
    "            new_labels.append(new_label)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return new_labels\n",
    "all_labels = []\n",
    "for label in labels:\n",
    "    all_labels.append(label)\n",
    "\n",
    "# Find the unique label values\n",
    "unique_labels = set(all_labels)\n",
    "\n",
    "# Print the unique label values\n",
    "print(\"Unique label values:\", unique_labels)\n",
    "label_map = {\n",
    "    'investment_company': 0,\n",
    "    'WHEREAS': 1,\n",
    "    'seed': 2,\n",
    "    'Insurance': 3,\n",
    "    'esop': 4,\n",
    "    'compensation': 5,\n",
    "    'Definitions': 6,\n",
    "    'financing': 7,\n",
    "    'payment_terms': 8,\n",
    "    'Headings': 9,\n",
    "    'loans': 10,\n",
    "    'shares': 11,\n",
    "    'Notices': 12,\n",
    "    'Severability': 13,\n",
    "    'taxes': 14,\n",
    "    'Assignment': 15,\n",
    "    'stock_option': 16,\n",
    "    'payment': 17,\n",
    "    'vesting': 18,\n",
    "    'Miscellaneous': 19,\n",
    "    'private_equity': 20,\n",
    "    'investments': 21,\n",
    "    'Governing': 22,\n",
    "    'interest': 23,\n",
    "    'grant_of_option': 24,\n",
    "    'conversion_of_shares': 25,\n",
    "    'foreign_investors': 26,\n",
    "    'Entire': 27,\n",
    "    'Termination': 28,\n",
    "    'Indemnification': 29,\n",
    "    'ownership_of_shares': 30,\n",
    "    'investment-company-act': 31,\n",
    "    'dividends': 32,\n",
    "    'grant': 33,\n",
    "    'base-salary': 34,\n",
    "    'NOW': 35,\n",
    "    'Representations': 36,\n",
    "    'Confidentiality': 37,\n",
    "    'board': 38,\n",
    "    'employee_benefits': 39,\n",
    "    'Counterparts': 40,\n",
    "    'capitalization': 41\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('google/bert_uncased_L-2_H-128_A-2')\n",
    "sentences = [str(sentence) for sentence in sentences]\n",
    "\n",
    "encoded_sentences = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContractsDataset(Dataset):\n",
    "    def __init__(self, encoded_sentences, labels):\n",
    "        self.input_ids = encoded_sentences[\"input_ids\"]\n",
    "        self.attention_mask = encoded_sentences[\"attention_mask\"]\n",
    "        self.labels = labels\n",
    "        self.label_map = {\n",
    "            'investment_company': 0,\n",
    "            'WHEREAS': 1,\n",
    "            'seed': 2,\n",
    "            'Insurance': 3,\n",
    "            'esop': 4,\n",
    "            'compensation': 5,\n",
    "            'Definitions': 6,\n",
    "            'financing': 7,\n",
    "            'payment_terms': 8,\n",
    "            'Headings': 9,\n",
    "            'loans': 10,\n",
    "            'shares': 11,\n",
    "            'Notices': 12,\n",
    "            'Severability': 13,\n",
    "            'taxes': 14,\n",
    "            'Assignment': 15,\n",
    "            'stock_option': 16,\n",
    "            'payment': 17,\n",
    "            'vesting': 18,\n",
    "            'Miscellaneous': 19,\n",
    "            'private_equity': 20,\n",
    "            'investments': 21,\n",
    "            'Governing': 22,\n",
    "            'interest': 23,\n",
    "            'grant_of_option': 24,\n",
    "            'conversion_of_shares': 25,\n",
    "            'foreign_investors': 26,\n",
    "            'Entire': 27,\n",
    "            'Termination': 28,\n",
    "            'Indemnification': 29,\n",
    "            'ownership_of_shares': 30,\n",
    "            'investment-company-act': 31,\n",
    "            'dividends': 32,\n",
    "            'grant': 33,\n",
    "            'base-salary': 34,\n",
    "            'NOW': 35,\n",
    "            'Representations': 36,\n",
    "            'Confidentiality': 37,\n",
    "            'board': 38,\n",
    "            'employee_benefits': 39,\n",
    "            'Counterparts': 40,\n",
    "            'capitalization': 41\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        label_id = self.label_map[self.labels[idx]]\n",
    "        return {\n",
    "                \"input_ids\": torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "                \"labels\": torch.tensor(label_id, dtype=torch.long)\n",
    "                }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the LinearBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.linear(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ContractsDataset(encoded_sentences, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = LinearBERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 21187\n",
      "Number of encoded sentences: 21187\n",
      "Number of labels: 21187\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))\n",
    "print(\"Number of encoded sentences:\", encoded_sentences[\"input_ids\"].shape[0])\n",
    "print(\"Number of labels:\", len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_4336\\124884580.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"input_ids\": torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_4336\\124884580.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"attention_mask\": torch.tensor(self.attention_mask[idx], dtype=torch.long),\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for data in dataloader:\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attention_mask = data[\"attention_mask\"].to(device)\n",
    "        labels = data[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * input_ids.size(0)\n",
    "        preds = torch.sigmoid(outputs.squeeze()) >= 0.5\n",
    "        running_corrects += torch.sum(preds == labels.byte())\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataset)\n",
    "    print('Epoch: {} Loss: {:.3f} Accuracy: {:.3f}'.format(epoch + 1, epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
